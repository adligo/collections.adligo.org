Scott to Heinz

Scott Morgan <scott@adligo.com>
Aug 11, 2021, 5:50 PM (2 days ago)
to Dr

Hi Heinz,

  I have been studying algorithms and CS a bit more, looking to implement
something like B-Trees;
https://en.wikipedia.org/wiki/B-tree

But in memory, and after some research it looks like 
a custom min heap and max heap with a custom doubly linked list would 
be the way to go (for the range chunk / pointers which could 
be ArrayLists). This would
give O(1) to get the max and min element.  It would provide O(log n)
lookup of any particular element, and then O(n) for a stream / sub set.

As I am looking to implement the heaps myself (so I would have access
to the heap as an index I am looking to use an ArrayList for the heap data.
Then I was looking at the source code for ArrayList;
  https://hg.openjdk.java.net/jdk8/jdk8/jdk/file/tip/src/share/classes/java/util/ArrayList.java

It seems to be doing a lot of this, in various places;
Arrays.copyOf

Isn't this fairly horrible in terms of Big O performance?  I.E I add or insert (add(40,50) ) a single element and all of a sudden I have O(n) where n is the number of items currently in the list.  Do you know why it wasn't implemented as a two dimensional array [][], so that only part of the list would need to be modified giving something more like O(c) (where c is the average chunk size) insert and add when the ensureCapacity 
needs to grow?
  Or am I just looking at really stale code (jdk8 vs 15), or am I missing something else here?

Also, here is some basic crap, that you can skip over :)  My initial 
attempt at the B-Tree (when I hadn't thought through the double min & max
heap solution).  
https://github.com/adligo/collections.adligo.org/blob/main/src/org/adligo/collections/shared/HashIndexMutant.java
But when I eventually do this it will end up here :)



Then Dr Heinz M. Kabutz replied;


your fear of linear cost of the copyOf() in ArrayList is misplaced IMHO :-) You should 
be far more concerned about the linear cost of the garbage collector. The linear 
cost of the copyOf() happens rarely. For example, if you insert 100_000_000 elements 
into an ArrayList, it will happen exactly 40 times, ending with an array of size 
110573323 ((int)(10 * Math.pow(1.5, 40))). Thus out of 100_000_000 inserts, you only 
have 40 that cost a little bit more than average. The GC will cause far more havoc than that.

If you wanted to, you could pre-size the ArrayList to the correct size, which makes a 
difference once the lists get very large. However, that would defeat the point of using 
a B-Tree, where you want the individual lists to be fairly small.
Here is some sample code that demonstrates the cost of expansion:
import java.util.*;
import java.util.function.*;

// 64 GB MacBook Pro
// -XX:+UseParallelGC -Xms20g -Xmx20g -XX:NewSize=16g
public class ArrayExpansionCost {
  public static void main(String... args) {
    List<IntFunction<List<String>>> listSuppliers = List.of(
        ArrayList::new,
        __ -> new ArrayList<>(),
        __ -> new LinkedList<>()
    );

    for (int i = 0; i < 10; i++) {
      for (IntFunction<List<String>> listSupplier : listSuppliers) {
        test(listSupplier);
      }
    }
  }

  private static void test(IntFunction<List<String>> listSupplier) {
    System.out.println(listSupplier.apply(0).getClass());
    for (int size = 1000; size <= 100_000_000; size *= 10) {
      long time = System.nanoTime();
      try {
        List<String> list = listSupplier.apply(size);
        for (int i = 0; i < size; i++) {
          list.add("value");
        }
      } finally {
        time = System.nanoTime() - time;
        System.out.printf(Locale.US,
            "size = %,d, time = %dms%n", size, (time / 1_000_000));
      }
      System.gc();
    }
    System.out.println();
  }
}

Final score:

class java.util.ArrayList
size = 1,000, time = 0ms
size = 10,000, time = 0ms
size = 100,000, time = 0ms
size = 1,000,000, time = 1ms
size = 10,000,000, time = 16ms
size = 100,000,000, time = 151ms

class java.util.ArrayList
size = 1,000, time = 0ms
size = 10,000, time = 0ms
size = 100,000, time = 0ms
size = 1,000,000, time = 3ms
size = 10,000,000, time = 37ms
size = 100,000,000, time = 323ms

class java.util.LinkedList
size = 1,000, time = 0ms
size = 10,000, time = 0ms
size = 100,000, time = 0ms
size = 1,000,000, time = 3ms
size = 10,000,000, time = 36ms
size = 100,000,000, time = 372ms

The first result is the pre-sized ArrayList. We can thus see that there is an 
additional cost in expansion, but it is minimal.

If I were implementing a B-Tree, I would probably start with ArrayList, but eventually 
end up using my own arrays. I would be interested in whether you will beat the 
ConcurrentSkipListSet with your implementation.
